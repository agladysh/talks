\documentclass[handout]{beamer}

\usepackage{minted}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[T1]{fontenc}

\mode<presentation>{
  \usetheme{default}
}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

\newcommand{\comment}[1]{}

%% -------------------------------------------------------------------------- %%

\title{Ad-hoc Big-Data Analysis with Lua}
\subtitle{And LuaJIT}
\author{\includegraphics[height=.4\textheight]{logo}}
\institute{Alexander Gladysh <ag@logiceditor.com>\newline@agladysh}
\date{Lua Workshop 2015\\Stockholm}

%% -------------------------------------------------------------------------- %%

\begin{document}

\maketitle

%% -------------------------------------------------------------------------- %%

\begin{frame}{Outline}

\tableofcontents

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{Introduction}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Alexander Gladysh}

\begin{itemize}
\item CTO, co-owner at LogicEditor
\item In l√∂ve with Lua since 2005
\end{itemize}

\end{frame}

\comment{

  TODO:
  -- Sort slides
  -- Introduce sections
  -- Add examples
  -- Run time stats
  -- Basics on work with sorted files
  -- Sort tricks

  Outline:

  1. Introduction
    Alexander Gladysh, CTO and co-owner of LogicEditor
  2. The elephant
    Define the problem. What is big data. Make small(er), more palatable, data
    from the big one. If you're big, you have hadoop and whatnot.
    If you're small, maybe you have google bigquery and analogs.

    But if you're small and have some modest computing power of your own
    and need to do some exploratory analysis, Lua to the rescue.
    As usual, go minimalistic then either pick existing tool you need
    or roll your own ecosystem.
    The workflow is to massage data and then feed it to more powerful analytics
    tool like R or even Excel.
  3. What hardware? Lots of memory, fast hdd / ssd,
  3. How data is stored.
    Files, synched across filesystems.
  4. Map-reduce, sort, join and friends (but you know them all)
    See also AA's ticket about combiners.
    Outline basic properties of the sorted data.
  5. The tools and the pipeline
    Some standard bash tools and LuaJIT (plain Lua would work too).
    Traditional alternatives to Lua: awk, perl are less maintainable for
    more complex scripts.
    There are always a few bash tools that you missed that could do the job
    better, faster etc. You can't know them all. I give you the basics.
  6. Sort
    + pre-sort stuff
    + join / sort -m, comm
    columns
  7. Uniq
  8. Grep
  9. cut, awk
  10. Lua.
    + memory limit
    + How the code looks like?
  11. Parallel
  12. Compression
    lxc for being fast
    pigz etc. for compatibility
    xz for size
  13. pv
    nifty diagnostics
  14. What's next?
    Hadoop
    FFI
  15. Questions?
}

%% -------------------------------------------------------------------------- %%

\section{The Problem}

%% -------------------------------------------------------------------------- %%

\begin{frame}{The Problem}

\begin{itemize}
\item You have a dataset to analyze,
\item which is too large for "small-data" tools,
\item and have no resources to setup and maintain (or pay for)
      the Hadoop, Google Big Query etc.
\item but you have some processing power available.
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{A Solution}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Goal}

\begin{itemize}
\item Pre-process the data so it can be handled by R or Excel or your favorite
analytics tool (or Lua!).
\item If the data is dynamic, then \textit{learn to} pre-process it
      and build a data processing pipeline.
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{An approach}

\begin{itemize}
\item Use Lua!
\item And (semi-)standard tools, available on Linux.
\item Go minimalistic while exploring,
\item Then move to an industrial solution that fits your newly understood
      requirements,
\item Or roll your own ecosystem! ;-)
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{Assumptions}

%% -------------------------------------------------------------------------- %%

\begin{frame}
\huge Assumptions
\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Data format}

\begin{itemize}
\item Plain text
\item Column-based (csv-like), optionally with free-form data in the end
\item Typical example: web-server log files
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Data Format Example: raw data}

\begin{minted}{text}
2015/10/15 16:35:30 [info] 14171#0: *901195
[lua] index:14: 95c1c06e626b47dfc705f8ee6695091a
109.74.197.145 *.example.net
GET 123456.gif?q=0&step=0&ref= HTTP/1.1 example.com
\end{minted}
\textit{NB: This is a single, tab-separated line from a time-sorted file.}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Data Format Example: intermediate data}

\begin{minted}{text}
alpha.example.com	5
beta.example.com	7
gamma.example.com	1
\end{minted}

\textit{NB: These are several tab-separated lines from a key-sorted file.}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Hardware}

\begin{itemize}
\item As usual, more is better: Cores, cache, memory speed and size,
      HDD speeds, networking speeds...
\item But even a modest VM (or several) can be helpful.
\item Your fancy gaming laptop is good too ;-)
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{OS}

\begin{itemize}
\item Linux (Ubuntu) Server.
\item Approach will, of course, work for other setups.
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Filesystem}

\begin{itemize}
\item Ideally, have data copies on each processing node, using identical
      layouts.
\item Fast network should work too.
\item Use of network filesystem of one kind or another are not a requirement.
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{The Tools}

%% -------------------------------------------------------------------------- %%

\begin{frame}
\huge The Tools
\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{The Tools}

\begin{itemize}
\item parallel
\item sort, uniq, grep
\item cut, join, comm
\item pv
\item compression utilities
\item LuaJIT
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{LuaJIT?}

Up to a point:
\begin{itemize}
\item 2.1 helps to speed things up,
\item FFI bogs down development speed.
\item Go plain Lua first (run it with LuaJIT),
\item then roll your own ecosystem as needed ;-)
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Parallel}

\begin{itemize}
\item xargs for parallel computation
\item can run your jobs in parallel on a single machine
\item or on a "cluster"
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Compression}

\begin{itemize}
\item gzip: default, bad
\item lxc: fast, large files
\item pigz: fast, parallelizable
\item xz: good compression, slow
\item ...and many more,
\item be on lookout for new formats!
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{Examples}

%% -------------------------------------------------------------------------- %%

\begin{frame}
\huge Examples
\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Bash script example}

\begin{minted}{bash}
time pv /path/to/uid-time-url-post.gz \
| pigz -cdp 4 \
| cut -d$'\t' -f 1,3 \
| parallel --gnu --progress -P 10 --pipe --block=16M \
  $(cat <<"EOF"
    luajit ~me/url-to-normalized-domain.lua
EOF
  ) \
| LC_ALL=C sort -u -t$'\t' -k2 --parallel 6 -S20% \
| luajit ~me/reduce-key-counter.lua \
| LC_ALL=C sort -t$'\t' -nrk2 --parallel 6 -S20% \
| pigz -cp4 >/path/to/domain-uniqs_count-merged.gz
\end{minted}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Lua Script Example: url-to-normalized-domain.lua}

\begin{minted}{bash}
for l in io.lines() do
  local key, value = l:match("^([^\t]+)\t(.*)")
  if value then
    value = url_to_normalized_domain(value)
  end
  if key and value then
    io.write(key, "\t", value, "\n")
  end
end
\end{minted}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Lua Script Example: reduce-key-counter.lua 1/3}

\begin{minted}{lua}
-- Assumes input sorted by VALUE
-- a  foo --> foo  3
-- a  foo     bar  2
-- b  foo     quo  1
-- a  bar
-- c  bar
-- d  quo
\end{minted}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Lua Script Example: reduce-key-counter.lua 2/3}

\begin{minted}{lua}
local last_key = nil, accum = 0

local flush = function(key)
  if last_key then
    io.write(last_key, "\t", accum, "\n")
  end
  accum = 0
  last_key = key -- may be nil
end
\end{minted}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}[fragile]{Lua Script Example: reduce-key-counter.lua 3/3}

\begin{minted}{lua}
for l in io.lines() do
  -- Note reverse order!
  local value, key = l:match("^(.-)\t(.*)$")
  assert(key and value)

  if key ~= last_key then
    flush(key)
    collectgarbage("step")
  end

  accum = accum + 1
end

flush()
\end{minted}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{Notes}

%% -------------------------------------------------------------------------- %%

\begin{frame}
\huge Notes and Remarks
\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Why Lua?}

Perl, AWK are traditional alternatives to Lua,
but, if you're not very disciplined and experienced,
they are much less maintainable.

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Start small!}

\begin{itemize}
\item Always run your scripts on small representative excerpts
      from your datasets, not only while developing them locally,
      but on actual data-processing nodes too.
\item Saves time and helps you learn the bottlenecks.
\item Sometimes large run still blows in your face though:
\item Monitor resource utilization at run-time.
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Discipline!}

\begin{itemize}
\item Many moving parts, large turn-around times, hard to keep tabs.
\item Keep journal: Write down what you run and what time it took.
\item Store actual versions of your scripts in a source control system.
\item Don't forget to sanity-check the results you get!
\end{itemize}

\end{frame}

%% -------------------------------------------------------------------------- %%

\section{Questions?}

%% -------------------------------------------------------------------------- %%

\begin{frame}{Questions?}

Alexander Gladysh,
ag@logiceditor.com

\end{frame}

%% -------------------------------------------------------------------------- %%

\end{document}

%% -------------------------------------------------------------------------- %%
